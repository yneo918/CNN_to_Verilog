{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbd8418e-b3fd-4ae5-a35e-0c5a949e193f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/use/bin/env python3.8.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c61429ea-bb6d-41e5-b773-ffa0825a8a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import datetime\n",
    "from torchstat import stat\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11a62568-bc99-43ed-a6af-c58514e71976",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, (5,5), bias = None)\n",
    "        self.conv2 = nn.Conv2d(6, 16, (5,5), bias = None)\n",
    "        self.fc1   = nn.Linear(16*5*5, 128, bias = None)\n",
    "        self.fc2   = nn.Linear(128, 84, bias = None)\n",
    "        self.fc3   = nn.Linear(84, 10, bias = None)\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2,2))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        loss = ((outputs - targets)**4).mean()\n",
    "        return loss   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb0a6df-125a-4a5d-9d8a-c4b471b2c5eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61cbe98e-a9d6-4a48-9287-26f23fb80b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net, test_loader, criterion, dtype=torch.float32):\n",
    "    test_acc = 0\n",
    "    test_loss = 0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            inputs = inputs.to(dtype)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()/len(test_loader)\n",
    "            acc = (outputs.argmax(dim=1) == labels).float().mean()\n",
    "            test_acc += acc/len(test_loader)\n",
    "    return test_acc, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf106027-b445-497d-9f5f-4e8e0eca97a6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "659002e8-2a42-481b-90b0-a9e58908929b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_grad(net, test_loader, train_loader, criterion, dtype=torch.float32):\n",
    "    test_acc = 0\n",
    "    test_loss = 0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            inputs = inputs.to(dtype)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()/len(test_loader)\n",
    "            acc = (outputs.argmax(dim=1) == labels).float().mean()\n",
    "            test_acc += acc/len(test_loader)\n",
    "    net.train()\n",
    "    for data in train_loader:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        inputs = inputs.to(dtype)\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "    return test_acc, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be9428bf-dbd4-4be5-9214-0dd79a3c679b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def to_int8(net_g,LOG):\n",
    "    net_g.conv1.weight.data = (net_g.conv1.weight.data*128).to(torch.int8).to(torch.float16)/128\n",
    "    net_g.conv2.weight.data = (net_g.conv2.weight.data*128).to(torch.int8).to(torch.float16)/128\n",
    "    net_g.fc1.weight.data = (net_g.fc1.weight.data*128).to(torch.int8).to(torch.float16)/128\n",
    "    net_g.fc2.weight.data = (net_g.fc2.weight.data*128).to(torch.int8).to(torch.float16)/128\n",
    "    net_g.fc3.weight.data = (net_g.fc3.weight.data*128).to(torch.int8).to(torch.float16)/128\n",
    "    LOG.append(\"to int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f838bd93-f237-444e-8d02-50fa37ae0b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "batch_size = 200\n",
    "DL = False\n",
    "train_set = torchvision.datasets.CIFAR10(root='~/work2/workspace/datasets/CIFAR-10', \n",
    "                                        train=True,\n",
    "                                        download=DL,\n",
    "                                        transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set,\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True,\n",
    "                                            num_workers=2)\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(root='~/work2/workspace/datasets/CIFAR-10/', \n",
    "                                        train=False, \n",
    "                                        download=DL, \n",
    "                                        transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, \n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=False, \n",
    "                                            num_workers=2)\n",
    "classes = tuple(np.linspace(0, 9, 10, dtype=np.uint8))\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "562d034a-4d0c-4457-adf9-5a00efe19fd4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "  (fc1): Linear(in_features=256, out_features=128, bias=False)\n",
      "  (fc2): Linear(in_features=128, out_features=84, bias=False)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/y-neo/.local/lib/python3.6/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "net = LeNet()\n",
    "print (net)\n",
    "\n",
    "LOAD_FLAG = True\n",
    "LOSS_FLAG = True\n",
    "MODEL_HOME = \"/home/y-neo/work2/workspace/docker/workspace/LeNet_MNIST\"\n",
    "\n",
    "net.to(device)\n",
    "\n",
    "pre_acc = 0\n",
    "pre_loss = 10\n",
    "\n",
    "INITIAL_LOAD=False\n",
    "if INITIAL_LOAD:\n",
    "    if os.path.exists('./acc'):\n",
    "        with open('./acc','r') as f:\n",
    "            t = f.read()\n",
    "        pre_acc = float(t)\n",
    "        print(pre_acc)\n",
    "        with open('./loss','r') as f:\n",
    "            t = f.read()\n",
    "        pre_loss = float(t)\n",
    "        print(pre_loss)\n",
    "\n",
    "        with open('./timestamp','r') as f:\n",
    "            t = f.read()\n",
    "\n",
    "        model_path = MODEL_HOME + '/model_'+t+'.pth'\n",
    "\n",
    "        # model_path = 'model.pth'\n",
    "        net.load_state_dict(torch.load(model_path))\n",
    "        print(model_path)\n",
    "\n",
    "for i in range(1,100):\n",
    "    o_file = './logs/'+str(i).zfill(3)+'.log'\n",
    "    if not os.path.exists(o_file):\n",
    "        OUTPUTFILE = open(o_file,'w')\n",
    "        OUTPUTFILE.write(str(i).zfill(3)+'\\n')\n",
    "        break\n",
    "        \n",
    "        \n",
    "o_data = './data.csv'\n",
    "with open(o_data, mode='a') as f:\n",
    "    f.write('Epoch,epoch_train_acc,epoch_train_loss,epoch_test_acc,epoch_test_loss,timestamp\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0da665f3-3169-4397-9c31-e9fd38e9b88d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 : train acc. 0.098 train loss 2.306\n",
      "Epoch 1 : test acc. 0.098 test loss 2.302\n",
      "Epoch 2 : train acc. 0.099 train loss 2.298\n",
      "Epoch 2 : test acc. 0.104 test loss 2.294\n",
      "Epoch 3 : train acc. 0.133 train loss 2.289\n",
      "Epoch 3 : test acc. 0.166 test loss 2.284\n",
      "Epoch 4 : train acc. 0.216 train loss 2.278\n",
      "Epoch 4 : test acc. 0.315 test loss 2.269\n",
      "Epoch 5 : train acc. 0.387 train loss 2.257\n",
      "Epoch 5 : test acc. 0.434 test loss 2.241\n",
      "Epoch 6 : train acc. 0.457 train loss 2.212\n",
      "Epoch 6 : test acc. 0.476 test loss 2.171\n",
      "Epoch 7 : train acc. 0.491 train loss 2.078\n",
      "Epoch 7 : test acc. 0.521 test loss 1.925\n",
      "Epoch 8 : train acc. 0.611 train loss 1.582\n",
      "Epoch 8 : test acc. 0.719 test loss 1.150\n",
      "Epoch 9 : train acc. 0.777 train loss 0.844\n",
      "Epoch 9 : test acc. 0.822 test loss 0.632\n",
      "Epoch 10 : train acc. 0.848 train loss 0.530\n",
      "Epoch 10 : test acc. 0.872 test loss 0.443\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "epochs = 10\n",
    "count = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_train_loss = 0\n",
    "    epoch_train_acc = 0\n",
    "    epoch_test_loss = 0\n",
    "    epoch_test_acc = 0\n",
    "    net.train()\n",
    "    for data in train_loader:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_train_loss += loss.item()/len(train_loader)\n",
    "        acc = (outputs.argmax(dim=1) == labels).float().mean()\n",
    "        epoch_train_acc += acc/len(train_loader)\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            epoch_test_loss += loss.item()/len(test_loader)\n",
    "            test_acc = (outputs.argmax(dim=1) == labels).float().mean()\n",
    "            epoch_test_acc += test_acc/len(test_loader)\n",
    "    print(f'Epoch {epoch+1} : train acc. {epoch_train_acc:.3f} train loss {epoch_train_loss:.3f}')\n",
    "    print(f'Epoch {epoch+1} : test acc. {epoch_test_acc:.3f} test loss {epoch_test_loss:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "379261b9-a313-4590-9ab7-7d1df8208567",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7, 6, 1, 0, 4, 1, 4, 9, 6, 9, 0, 6, 9, 0, 1, 5, 9, 7, 5, 4, 7, 6, 4, 5,\n",
      "        9, 0, 7, 4, 0, 1, 3, 1, 5, 0, 7, 2, 7, 1, 2, 1, 1, 7, 4, 2, 3, 5, 3, 2,\n",
      "        9, 4, 6, 3, 5, 5, 4, 0, 4, 1, 9, 5, 7, 8, 9, 7, 7, 9, 2, 4, 3, 0, 7, 0,\n",
      "        2, 7, 1, 7, 3, 7, 7, 7, 9, 6, 2, 7, 8, 4, 7, 5, 6, 1, 3, 6, 7, 3, 1, 4,\n",
      "        3, 1, 6, 9], device='cuda:0')\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for data in test_loader:\n",
    "    inputs, labels = data[0], data[1]\n",
    "    img = inputs[0].numpy().reshape((28, 28))\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.show()\n",
    "    inputs, labels = data[0].to(device), data[1].to(device)\n",
    "    outputs = net(inputs)\n",
    "    #print(outputs)\n",
    "    print(outputs.argmax(dim=1))\n",
    "    loss = criterion(outputs, labels)\n",
    "    print(net.fc3.weight.grad)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76497a72-b3c3-47b1-a198-20ef52176b8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LOG = []\n",
    "net_g = LeNet()\n",
    "net_g.to(device)\n",
    "net_g.conv1.weight.data = net_g.conv1.weight.data.to(torch.float16)\n",
    "net_g.conv2.weight.data = net_g.conv2.weight.data.to(torch.float16)\n",
    "net_g.fc1.weight.data = net_g.fc1.weight.data.to(torch.float16)\n",
    "net_g.fc2.weight.data = net_g.fc2.weight.data.to(torch.float16)\n",
    "net_g.fc3.weight.data = net_g.fc3.weight.data.to(torch.float16)\n",
    "LOG.append(\"init float16\")\n",
    "cur = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ed021ac-45be-4f31-af7d-7d606f2278bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net_g.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4268f9fc-b310-4234-848f-af286fc854ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_g.conv1.weight.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "575b9672-72ad-4897-981b-fb115d4fcc5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 : train acc. 0.109 train loss 2.303\n",
      "Epoch 1 : test acc. 0.102 test loss 2.303\n",
      "Epoch 2 : train acc. 0.111 train loss 2.303\n",
      "Epoch 2 : test acc. 0.123 test loss 2.302\n",
      "Epoch 3 : train acc. 0.127 train loss 2.302\n",
      "Epoch 3 : test acc. 0.126 test loss 2.302\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-3d3f66c6a76e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mepoch_train_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mepoch_train_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "count = 0\n",
    "saturated = 0\n",
    "for epoch in range(epochs):\n",
    "    epoch_train_loss = 0\n",
    "    epoch_train_acc = 0\n",
    "    epoch_test_loss = 0\n",
    "    epoch_test_acc = 0\n",
    "    net_g.train()\n",
    "    for data in train_loader:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        inputs = inputs.to(torch.float16)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net_g(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_train_loss += loss.item()/len(train_loader)\n",
    "        acc = (outputs.argmax(dim=1) == labels).float().mean()\n",
    "        epoch_train_acc += acc/len(train_loader)\n",
    "    net_g.eval()\n",
    "    to_int8(net_g,LOG)\n",
    "    epoch_test_acc, epoch_test_loss = test(net_g, test_loader, criterion, torch.float16)\n",
    "    print(f'Epoch {epoch+1} : train acc. {epoch_train_acc:.3f} train loss {epoch_train_loss:.3f}')\n",
    "    print(f'Epoch {epoch+1} : test acc. {epoch_test_acc:.3f} test loss {epoch_test_loss:.3f}')\n",
    "    if cur < epoch_test_acc:\n",
    "        cur = epoch_test_acc\n",
    "        MODEL_HOME = \"/home/y-neo/work2/workspace/docker/workspace/LeNet_CIFAR10\"\n",
    "        model_path = MODEL_HOME + '/model_trainingp.pth'\n",
    "        torch.save(net_g.state_dict(), model_path)\n",
    "    else:\n",
    "        saturated += 1\n",
    "        if saturated > 3:\n",
    "            print(\"break\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "bb372abf-51db-407a-9245-5ab7d40634a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test acc. 0.581 test loss 1.217\n"
     ]
    }
   ],
   "source": [
    "net_g.eval()\n",
    "to_int8(net_g,LOG)\n",
    "test_acc, test_loss = test(net_g, test_loader, criterion, torch.float16)\n",
    "print(f' test acc. {test_acc:.3f} test loss {test_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1ef8d891-d00e-48ce-acfa-150e3940e9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_HOME = \"/home/y-neo/work2/workspace/docker/workspace/LeNet_CIFAR10\"\n",
    "model_path = MODEL_HOME + '/model_training.pth'\n",
    "net_g.load_state_dict(torch.load(model_path))\n",
    "LOG = []\n",
    "LOG.append(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a7a3f1-5662-4e8c-9bb3-ef03bd9defd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_HOME = \"/home/y-neo/work2/workspace/docker/workspace/LeNet_CIFAR10\"\n",
    "model_path = MODEL_HOME + '/model.pth'\n",
    "torch.save(net_g.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2da8fd4d-1200-4772-9e9d-e8083b7d3a91",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ans = truck, LeNet_Ans = airplane\n",
      "Ans = dog, LeNet_Ans = dog\n",
      "Ans = automobile, LeNet_Ans = automobile\n",
      "Ans = cat, LeNet_Ans = deer\n",
      "Ans = ship, LeNet_Ans = ship\n",
      "Ans = horse, LeNet_Ans = deer\n",
      "Ans = bird, LeNet_Ans = frog\n",
      "Ans = dog, LeNet_Ans = dog\n",
      "Ans = automobile, LeNet_Ans = automobile\n",
      "Ans = horse, LeNet_Ans = horse\n",
      "Ans = frog, LeNet_Ans = truck\n",
      "Ans = horse, LeNet_Ans = dog\n",
      "Ans = cat, LeNet_Ans = dog\n",
      "Ans = airplane, LeNet_Ans = truck\n",
      "Ans = dog, LeNet_Ans = dog\n",
      "Ans = deer, LeNet_Ans = bird\n",
      "Ans = horse, LeNet_Ans = horse\n",
      "Ans = dog, LeNet_Ans = dog\n",
      "Ans = ship, LeNet_Ans = automobile\n",
      "Ans = airplane, LeNet_Ans = airplane\n",
      "Ans = horse, LeNet_Ans = horse\n",
      "Ans = deer, LeNet_Ans = cat\n",
      "Ans = horse, LeNet_Ans = horse\n",
      "Ans = cat, LeNet_Ans = frog\n",
      "Ans = horse, LeNet_Ans = bird\n",
      "Ans = dog, LeNet_Ans = horse\n",
      "Ans = deer, LeNet_Ans = dog\n",
      "Ans = cat, LeNet_Ans = frog\n",
      "Ans = deer, LeNet_Ans = frog\n",
      "Ans = bird, LeNet_Ans = dog\n",
      "Ans = airplane, LeNet_Ans = bird\n",
      "Ans = deer, LeNet_Ans = cat\n",
      "Ans = automobile, LeNet_Ans = automobile\n",
      "Ans = bird, LeNet_Ans = bird\n",
      "Ans = ship, LeNet_Ans = ship\n",
      "Ans = airplane, LeNet_Ans = airplane\n",
      "Ans = dog, LeNet_Ans = cat\n",
      "Ans = truck, LeNet_Ans = automobile\n",
      "Ans = cat, LeNet_Ans = cat\n",
      "Ans = cat, LeNet_Ans = dog\n",
      "Ans = airplane, LeNet_Ans = airplane\n",
      "Ans = truck, LeNet_Ans = truck\n",
      "Ans = cat, LeNet_Ans = truck\n",
      "Ans = automobile, LeNet_Ans = automobile\n",
      "Ans = bird, LeNet_Ans = bird\n",
      "Ans = frog, LeNet_Ans = frog\n",
      "Ans = bird, LeNet_Ans = cat\n",
      "Ans = airplane, LeNet_Ans = airplane\n",
      "Ans = dog, LeNet_Ans = dog\n",
      "Ans = bird, LeNet_Ans = bird\n",
      "Ans = bird, LeNet_Ans = frog\n",
      "Ans = bird, LeNet_Ans = automobile\n",
      "Ans = horse, LeNet_Ans = horse\n",
      "Ans = truck, LeNet_Ans = truck\n",
      "Ans = bird, LeNet_Ans = bird\n",
      "Ans = horse, LeNet_Ans = horse\n",
      "Ans = cat, LeNet_Ans = ship\n",
      "Ans = cat, LeNet_Ans = cat\n",
      "Ans = airplane, LeNet_Ans = airplane\n",
      "Ans = dog, LeNet_Ans = cat\n",
      "Ans = deer, LeNet_Ans = deer\n",
      "Ans = truck, LeNet_Ans = truck\n",
      "Ans = cat, LeNet_Ans = frog\n",
      "Ans = bird, LeNet_Ans = airplane\n",
      "Ans = airplane, LeNet_Ans = airplane\n",
      "Ans = deer, LeNet_Ans = bird\n",
      "Ans = cat, LeNet_Ans = cat\n",
      "Ans = airplane, LeNet_Ans = airplane\n",
      "Ans = bird, LeNet_Ans = dog\n",
      "Ans = bird, LeNet_Ans = dog\n",
      "Ans = horse, LeNet_Ans = horse\n",
      "Ans = deer, LeNet_Ans = horse\n",
      "Ans = frog, LeNet_Ans = frog\n",
      "Ans = bird, LeNet_Ans = bird\n",
      "Ans = truck, LeNet_Ans = cat\n",
      "Ans = truck, LeNet_Ans = truck\n",
      "Ans = dog, LeNet_Ans = dog\n",
      "Ans = deer, LeNet_Ans = deer\n",
      "Ans = bird, LeNet_Ans = bird\n",
      "Ans = cat, LeNet_Ans = ship\n",
      "Ans = frog, LeNet_Ans = frog\n",
      "Ans = horse, LeNet_Ans = horse\n",
      "Ans = horse, LeNet_Ans = horse\n",
      "Ans = frog, LeNet_Ans = frog\n",
      "Ans = frog, LeNet_Ans = frog\n",
      "Ans = automobile, LeNet_Ans = automobile\n",
      "Ans = ship, LeNet_Ans = ship\n",
      "Ans = frog, LeNet_Ans = frog\n",
      "Ans = ship, LeNet_Ans = ship\n",
      "Ans = frog, LeNet_Ans = frog\n",
      "Ans = deer, LeNet_Ans = horse\n",
      "Ans = airplane, LeNet_Ans = airplane\n",
      "Ans = airplane, LeNet_Ans = airplane\n",
      "Ans = ship, LeNet_Ans = ship\n",
      "Ans = dog, LeNet_Ans = dog\n",
      "Ans = truck, LeNet_Ans = airplane\n",
      "Ans = cat, LeNet_Ans = cat\n",
      "Ans = automobile, LeNet_Ans = automobile\n",
      "Ans = ship, LeNet_Ans = ship\n",
      "Ans = bird, LeNet_Ans = bird\n",
      "tensor(0.6100, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "batch_size = 100\n",
    "test_loader_view = torch.utils.data.DataLoader(test_set, \n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True, \n",
    "                                            num_workers=2)\n",
    "sel = 0\n",
    "for data in test_loader_view:\n",
    "    for sel in range(batch_size):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        inputs = inputs.to(torch.float16)\n",
    "        outputs = net_g(inputs)\n",
    "        image = data[0][sel]/2+0.5\n",
    "        image = image.numpy()\n",
    "        image = np.transpose(image, (1, 2, 0))\n",
    "        classes = test_set.classes\n",
    "        print(\"Ans = {}\".format(classes[data[1][sel]]),end=\", \")\n",
    "        print(\"LeNet_Ans = {}\".format(classes[outputs.argmax(dim=1)[sel]]))\n",
    "        plt.imshow(image)\n",
    "        plt.show\n",
    "    print((outputs.argmax(dim=1) == labels).float().mean())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8f9b5cb-264c-40ac-90af-119857a1434c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_HOME = \"/home/y-neo/work2/workspace/auto_optim/data_flex_c10/conv1_1.7_1\"\n",
    "model_path = MODEL_HOME + '/model_retrained.pth'\n",
    "net_g.load_state_dict(torch.load(model_path))\n",
    "LOG = []\n",
    "LOG.append(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59cff0a5-0712-4646-b4b3-2d653ee82c79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_HOME = \"/home/y-neo/work2/workspace/docker/workspace/LeNet_CIFAR10\"\n",
    "model_path = MODEL_HOME + '/model.pth'\n",
    "\n",
    "net_g.load_state_dict(torch.load(model_path))\n",
    "LOG = []\n",
    "LOG.append(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cec10f93-ce74-4673-95a5-e4e4e91e392f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_HOME = \"/home/y-neo/work2/workspace/auto_optim/new/\"\n",
    "model_path = MODEL_HOME + '/model.pth'\n",
    "torch.save(net_g.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca9e928-44b6-48f2-b79f-f6dcf38873ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_HOME = \"/home/y-neo/work2/workspace/docker/workspace/LeNet_CIFAR10\"\n",
    "model_path = MODEL_HOME + '/model.pth'\n",
    "torch.save(net_g.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "01aa6b9d-f1eb-4118-be24-5796d5a81228",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_HOME = \"/home/y-neo/work2/workspace/docker/workspace/LeNet_CIFAR10\"\n",
    "model_path = MODEL_HOME + '/model_quant_int8.pth'\n",
    "net_g.load_state_dict(torch.load(model_path))\n",
    "LOG = []\n",
    "LOG.append(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1563b4a2-d637-4787-b5a6-2ee97eac5cb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_g.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7ae4540a-300f-404c-9bd3-21796a6c2945",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_HOME = \"/home/y-neo/work2/workspace/docker/workspace/LeNet_CIFAR10\"\n",
    "model_path = MODEL_HOME + '/model_quant_int8.pth'\n",
    "#torch.save(net_g.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27359aaa-afe5-4bf0-9fb4-3a1a5675fc33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/y-neo/work2/workspace/auto_optim/new/grad/fc3_grad']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(net_g.conv1.weight.grad, \"/home/y-neo/work2/workspace/auto_optim/new/grad/conv1_grad\",compress=3)\n",
    "joblib.dump(net_g.conv2.weight.grad, \"/home/y-neo/work2/workspace/auto_optim/new/grad/conv2_grad\",compress=3)\n",
    "joblib.dump(net_g.fc1.weight.grad, \"/home/y-neo/work2/workspace/auto_optim/new/grad/fc1_grad\",compress=3)\n",
    "joblib.dump(net_g.fc2.weight.grad, \"/home/y-neo/work2/workspace/auto_optim/new/grad/fc2_grad\",compress=3)\n",
    "joblib.dump(net_g.fc2.weight.grad, \"/home/y-neo/work2/workspace/auto_optim/new/grad/fc3_grad\",compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89c7a3ac-588b-4f88-95e6-0ab8117c2547",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/y-neo/work2/workspace/auto_optim/data_flex_c10/conv1_1.7_1/model_retrained.pth', 'to int8', 'to int8', 'to int8', 'to int8', 'to int8']\n",
      "test acc. 0.637 test loss 1.063\n"
     ]
    }
   ],
   "source": [
    "print(LOG)\n",
    "epoch_test_acc, epoch_test_loss = test_grad(net_g, test_loader, train_loader, criterion, torch.float16)\n",
    "print(f'test acc. {epoch_test_acc:.3f} test loss {epoch_test_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5233ee5a-8e6b-47c7-9266-c50743f16191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/y-neo/work2/workspace/docker/workspace/LeNet_CIFAR10/model_training.pth', 'to int8']\n",
      "test acc. 0.581 test loss 1.217\n"
     ]
    }
   ],
   "source": [
    "print(LOG)\n",
    "epoch_test_acc, epoch_test_loss = test_grad(net_g, test_loader, train_loader, criterion, torch.float16)\n",
    "print(f'test acc. {epoch_test_acc:.3f} test loss {epoch_test_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f644a16-fd51-4d58-ae94-0c346ae8f6af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# to int8\n",
    "net_g.conv1.weight.data = (net_g.conv1.weight.data*128).to(torch.int8).to(torch.float16)/128\n",
    "net_g.conv2.weight.data = (net_g.conv2.weight.data*128).to(torch.int8).to(torch.float16)/128\n",
    "net_g.fc1.weight.data = (net_g.fc1.weight.data*128).to(torch.int8).to(torch.float16)/128\n",
    "net_g.fc2.weight.data = (net_g.fc2.weight.data*128).to(torch.int8).to(torch.float16)/128\n",
    "net_g.fc3.weight.data = (net_g.fc3.weight.data*128).to(torch.int8).to(torch.float16)/128\n",
    "LOG.append(\"to int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f54967dc-cb76-4585-9e0a-6432fd398215",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num += 1\n",
    "MODEL_HOME = \"/home/y-neo/work2/workspace/optim/data/conv1_\"+str(num).zfill(2)\n",
    "model_path = MODEL_HOME + '/model_quant_int8.pth'\n",
    "torch.save(net_g.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "124f8435-ad50-4af5-b03c-69c8b890bc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "tmp_layer = copy.deepcopy(net_g.fc3.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "b14834a2-8067-462c-8f06-4193a76e0fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_g.fc3.weight.data = tmp_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4ba5532a-d125-4dc4-a680-e9a53b7fdbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_g.conv1.weight.data = (net_g.conv1.weight.data*128).to(torch.int8).to(torch.float16)/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e1d880d9-1cf8-4344-a96c-802eabdf9131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_g.conv1.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "id": "3ed68b3b-788e-4f46-baef-f7a20c13baff",
   "metadata": {},
   "outputs": [],
   "source": [
    "post = copy.deepcopy(net_g.conv1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243cce70-e663-4e9a-ba57-f72802b9ee09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a974ccba-66e9-449d-9a2a-01f839c3f6db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/y-neo/work2/workspace/auto_optim/data_flex_c10/conv1_1.7_1/model_retrained.pth', 'to int8', 'to int8', 'to int8', 'to int8', 'to int8']\n",
      "tensor([[[-30., -36., -48.,  -9.,   7.],\n",
      "         [-44., -34.,   0.,  23.,   5.],\n",
      "         [-24.,  -2.,   0.,   3.,   3.],\n",
      "         [-35., -12., -22.,  -9., -36.],\n",
      "         [-35., -23., -24., -25., -27.]],\n",
      "\n",
      "        [[-28., -44., -24.,   1.,   0.],\n",
      "         [-26., -14.,   0.,  22.,   2.],\n",
      "         [ -5.,  10.,  30.,  15.,   0.],\n",
      "         [  0.,   2.,   7., -11., -23.],\n",
      "         [ -9.,  -1.,   7.,  -3., -44.]],\n",
      "\n",
      "        [[ -2.,  -1.,  18.,  38.,  34.],\n",
      "         [ -6.,  24.,  44.,  54.,  48.],\n",
      "         [  4.,  44.,  52.,  53.,   9.],\n",
      "         [ 37.,  40.,  42.,  37.,  -7.],\n",
      "         [ 33.,  41.,  20.,  10., -17.]]], device='cuda:0',\n",
      "       dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "print(LOG)\n",
    "print(net_g.conv1.weight.data[0]*128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "facf2bc8-8622-4d9c-b3ac-346dc12028f4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/y-neo/work2/workspace/docker/workspace/LeNet_MNIST/model_quant_int8.pth', 'fc3_load']\n",
      "tensor([ 0.0391, -0.0938,  0.0000,  0.0703,  0.1016,  0.0000, -0.0703,  0.0938,\n",
      "         0.0078, -0.0781, -0.0078,  0.0078,  0.0625, -0.0781,  0.0078,  0.0469,\n",
      "         0.0391,  0.0859,  0.0156, -0.0156,  0.0625, -0.0469, -0.0078,  0.0000,\n",
      "        -0.0391, -0.0859, -0.0938, -0.0859,  0.0000, -0.0391,  0.0625, -0.0078,\n",
      "        -0.0547,  0.0078,  0.0625,  0.0703,  0.0000, -0.0156,  0.1016,  0.0547,\n",
      "         0.0469,  0.0547, -0.0312, -0.0469,  0.0938,  0.0547, -0.0859,  0.1094,\n",
      "         0.0781,  0.0625,  0.0000,  0.0000,  0.0234,  0.0391,  0.1016, -0.0625,\n",
      "        -0.1406, -0.0469,  0.0625,  0.0000, -0.0078, -0.0703,  0.0469, -0.0781,\n",
      "         0.0000,  0.0469,  0.0000,  0.0000,  0.0156,  0.0312,  0.0781, -0.0312,\n",
      "        -0.0938,  0.0000,  0.0000,  0.0625,  0.0547,  0.0312, -0.0703, -0.0625,\n",
      "         0.0156,  0.0469,  0.1250, -0.0234,  0.0000, -0.0391,  0.0000, -0.0547,\n",
      "        -0.0078,  0.0000, -0.1172,  0.1016,  0.1016, -0.0781, -0.0078,  0.0625,\n",
      "         0.0234, -0.0625,  0.0078,  0.0547, -0.0625,  0.0391,  0.1094, -0.0547,\n",
      "         0.0703, -0.0703,  0.0000,  0.0156,  0.0156,  0.0000,  0.0547, -0.0312,\n",
      "         0.0000,  0.0859, -0.0781,  0.0000, -0.0703,  0.0234,  0.0234, -0.0312,\n",
      "         0.0000,  0.1406,  0.0000, -0.0391,  0.0000, -0.0391,  0.0469, -0.0625],\n",
      "       device='cuda:0', dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "print(LOG)\n",
    "print(net_g.fc2.weight.data[83])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "id": "c52548d4-14de-4873-b96b-93f5641c42f0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/y-neo/work2/workspace/optim/model_quant_int8.pth', 'conv1_load', 'conv1_load', 'conv1_load', 'conv1_load', 'conv1_load', 'to int8', 'conv1_load', 'to int8', 'conv1_load', 'to int8', 'conv2_load']\n",
      "tensor([[[[ 3.5229e-03,  5.1308e-03,  5.2834e-03,  2.7752e-03,  2.8443e-04],\n",
      "          [ 5.6229e-03,  5.9738e-03,  5.9967e-03,  9.7418e-04, -3.2926e-04],\n",
      "          [ 4.6921e-03,  3.3569e-03,  5.4665e-03, -1.6069e-04, -2.7561e-04],\n",
      "          [ 2.0199e-03,  4.5538e-04,  2.2869e-03, -8.1348e-04,  1.3094e-03],\n",
      "          [ 1.6963e-04,  4.0817e-04,  5.7554e-04, -6.4135e-04,  1.7681e-03]],\n",
      "\n",
      "         [[ 2.2144e-03, -1.2655e-03, -2.7447e-03, -1.4715e-03,  1.6584e-03],\n",
      "          [ 4.1318e-04, -1.9665e-03, -3.7060e-03,  2.3067e-04,  3.6278e-03],\n",
      "          [-5.4359e-04,  3.2067e-04, -3.4904e-04,  1.9894e-03,  3.6774e-03],\n",
      "          [ 7.8201e-04,  2.4395e-03,  1.2884e-03,  3.0861e-03,  3.1872e-03],\n",
      "          [ 4.1962e-03,  4.0169e-03,  2.3346e-03,  4.0855e-03,  4.5166e-03]],\n",
      "\n",
      "         [[ 8.2684e-04,  2.2354e-03,  1.3752e-03,  1.9989e-03, -1.8418e-05],\n",
      "          [ 1.7920e-03,  1.6108e-03,  1.9083e-03,  2.0847e-03, -1.7464e-04],\n",
      "          [ 1.9646e-03,  1.5612e-03,  2.5482e-03,  1.4582e-03,  1.7881e-06],\n",
      "          [ 1.0862e-03,  2.7537e-04,  7.4339e-04,  8.8167e-04,  5.0688e-04],\n",
      "          [ 4.4918e-04,  6.1095e-05,  9.3079e-04,  9.6703e-04,  4.9448e-04]],\n",
      "\n",
      "         [[ 1.2093e-03,  2.2984e-03,  3.8681e-03,  2.8629e-03,  6.6948e-04],\n",
      "          [ 2.0256e-03,  1.3905e-03,  1.7519e-03,  5.2166e-04, -4.6062e-04],\n",
      "          [ 1.6546e-03,  1.0233e-03,  1.2541e-03,  2.7466e-04,  4.2009e-04],\n",
      "          [ 3.3259e-04,  2.4271e-04,  9.6178e-04, -3.3140e-04,  2.1911e-04],\n",
      "          [-9.5797e-04, -3.4380e-04,  5.5408e-04,  1.3399e-04,  7.7903e-05]],\n",
      "\n",
      "         [[ 5.9891e-04,  9.6989e-04, -5.6458e-04,  2.3060e-03,  3.4599e-03],\n",
      "          [-3.9744e-04, -5.2023e-04,  1.1313e-04,  4.6158e-03,  4.3602e-03],\n",
      "          [-3.1590e-04,  7.8535e-04, -4.8590e-04,  3.6011e-03,  4.2572e-03],\n",
      "          [ 1.2054e-03,  2.7885e-03, -8.7452e-04,  2.4109e-03,  2.0409e-03],\n",
      "          [ 2.7924e-03,  2.1935e-03, -1.0757e-03,  1.2636e-03,  9.7561e-04]],\n",
      "\n",
      "         [[ 1.5192e-03,  1.5402e-03,  3.0518e-04,  2.1839e-03,  3.0842e-03],\n",
      "          [ 1.4982e-03,  4.9362e-03,  6.2408e-03,  5.8060e-03,  5.4245e-03],\n",
      "          [ 2.1667e-03,  5.1460e-03,  7.3547e-03,  7.3128e-03,  2.5482e-03],\n",
      "          [ 1.9321e-03,  3.4790e-03,  5.5008e-03,  4.1504e-03,  2.3994e-03],\n",
      "          [ 5.9319e-03,  5.7030e-03,  3.8433e-03,  2.6531e-03,  3.8471e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6708e-03, -1.7653e-03, -5.1880e-04,  1.4420e-03,  1.9121e-04],\n",
      "          [-7.6580e-04, -5.6219e-04, -2.3251e-03,  3.2139e-04,  5.7507e-04],\n",
      "          [ 4.1270e-04,  1.0967e-03, -1.3247e-03,  4.7374e-04,  8.5068e-04],\n",
      "          [ 1.6870e-03,  8.4734e-04, -2.0237e-03,  8.0204e-04,  5.0831e-04],\n",
      "          [ 2.6989e-04, -1.7118e-03, -1.7118e-03, -1.1587e-03, -1.2255e-03]],\n",
      "\n",
      "         [[-1.2732e-03, -8.2552e-05,  1.8139e-03,  6.5374e-04,  1.4563e-03],\n",
      "          [-9.1410e-04, -2.7609e-04,  3.1929e-03,  2.6836e-03,  7.6151e-04],\n",
      "          [ 1.5879e-03, -5.0831e-04,  2.5711e-03,  2.1801e-03, -3.0565e-04],\n",
      "          [ 7.1812e-04, -7.5150e-04,  2.4414e-03,  1.3475e-03,  3.3593e-04],\n",
      "          [-2.0065e-03, -3.9029e-04,  2.7084e-03,  2.5501e-03,  2.1687e-03]],\n",
      "\n",
      "         [[ 4.0889e-04,  1.8144e-04,  5.2643e-04,  4.0364e-04, -1.1599e-04],\n",
      "          [-8.5545e-04, -5.7220e-06, -7.3576e-04, -9.5224e-04,  5.7602e-04],\n",
      "          [-7.0810e-04,  1.1053e-03, -2.8181e-04, -1.2712e-03, -2.3973e-04],\n",
      "          [-8.0013e-04,  5.2023e-04, -1.2617e-03, -1.5855e-04, -1.5807e-04],\n",
      "          [-5.9414e-04, -9.0075e-04, -7.9060e-04, -3.4499e-04, -5.4979e-04]],\n",
      "\n",
      "         [[ 5.6648e-04, -5.9843e-04, -6.3705e-04, -3.0065e-04, -6.3360e-05],\n",
      "          [-9.4175e-04, -1.0338e-03, -1.1128e-04,  5.2500e-04,  9.2459e-04],\n",
      "          [-7.4196e-04, -6.3992e-04, -5.8889e-04,  3.1173e-05,  2.6560e-04],\n",
      "          [ 1.3103e-03,  3.2377e-04, -1.0262e-03,  9.2030e-05, -7.1144e-04],\n",
      "          [ 1.0414e-03, -3.2783e-04, -8.6832e-04, -1.8187e-03, -2.2392e-03]],\n",
      "\n",
      "         [[-4.5300e-06,  9.5272e-04,  1.0300e-03, -1.1473e-03, -2.2006e-04],\n",
      "          [-2.8944e-04,  3.6073e-04,  1.9760e-03, -3.2687e-04, -2.1801e-03],\n",
      "          [-3.1567e-04,  8.0347e-04,  3.1109e-03,  2.7657e-05, -1.5793e-03],\n",
      "          [-1.2465e-03, -1.6260e-03,  1.4534e-03,  2.7633e-04, -7.7772e-04],\n",
      "          [-3.1738e-03, -1.6987e-04,  1.6623e-03, -1.0328e-03, -1.2941e-03]],\n",
      "\n",
      "         [[-2.0466e-03, -1.6012e-03,  1.8473e-03,  5.6648e-03,  4.0245e-03],\n",
      "          [ 2.7905e-03,  1.0710e-03,  9.6130e-04,  2.7490e-04, -4.0889e-05],\n",
      "          [ 1.2541e-03,  1.9169e-04, -1.1930e-03, -1.0815e-03, -1.1988e-03],\n",
      "          [-3.7708e-03, -1.2484e-03,  1.3351e-04,  1.2751e-03,  2.9564e-03],\n",
      "          [-1.9417e-03, -9.6512e-04,  9.6321e-05,  1.5621e-03,  1.9064e-03]]],\n",
      "\n",
      "\n",
      "        [[[-3.0251e-03, -5.8460e-04, -1.0155e-02, -1.4610e-02, -8.1177e-03],\n",
      "          [-3.9368e-03, -8.9264e-03, -1.8127e-02, -1.3626e-02, -5.2834e-03],\n",
      "          [-6.2103e-03, -1.8845e-02, -2.1484e-02, -6.4201e-03, -3.7308e-03],\n",
      "          [-9.4757e-03, -1.9913e-02, -1.2680e-02, -1.1845e-03, -3.8948e-03],\n",
      "          [-8.7357e-03, -1.2970e-02, -5.9433e-03, -2.7599e-03, -4.4403e-03]],\n",
      "\n",
      "         [[-9.6970e-03, -1.0857e-02, -8.4381e-03, -2.6302e-03, -2.3918e-03],\n",
      "          [-1.1482e-02, -1.1261e-02, -9.0122e-04,  1.3952e-03, -3.6430e-03],\n",
      "          [-1.3245e-02, -4.8828e-03,  3.7518e-03, -1.7567e-03, -9.0714e-03],\n",
      "          [-9.4223e-03,  2.1343e-03,  2.7409e-03, -7.4539e-03, -1.2306e-02],\n",
      "          [-5.2948e-03, -2.8362e-03, -6.8817e-03, -9.6817e-03, -1.1780e-02]],\n",
      "\n",
      "         [[-1.1997e-03, -3.1781e-04, -1.0338e-03, -5.6305e-03, -3.1853e-03],\n",
      "          [-1.5240e-03, -2.3422e-03, -6.0692e-03, -7.0763e-03, -3.6316e-03],\n",
      "          [-1.0490e-03, -4.5242e-03, -9.0485e-03, -4.5433e-03, -2.6646e-03],\n",
      "          [-5.6362e-04, -6.8092e-03, -6.5651e-03, -2.8133e-03, -2.9488e-03],\n",
      "          [-2.3594e-03, -5.1117e-03, -4.8637e-03, -2.9030e-03, -2.6741e-03]],\n",
      "\n",
      "         [[-1.4648e-03, -4.1008e-04, -5.5199e-03, -8.5220e-03, -4.9858e-03],\n",
      "          [ 8.0109e-04, -2.5253e-03, -8.4915e-03, -6.0577e-03, -2.0676e-03],\n",
      "          [-1.5907e-03, -8.1482e-03, -8.9035e-03, -4.0627e-03, -1.8053e-03],\n",
      "          [-6.3896e-03, -8.2397e-03, -4.8981e-03, -1.8444e-03, -2.7828e-03],\n",
      "          [-3.2082e-03, -2.9659e-03, -7.2527e-04, -2.3956e-03, -3.7556e-03]],\n",
      "\n",
      "         [[-8.6403e-04, -3.6240e-03, -2.5501e-03, -8.6355e-04, -4.6997e-03],\n",
      "          [-2.0027e-03, -4.1580e-03, -2.4014e-03, -3.7212e-03, -7.5912e-03],\n",
      "          [-3.8033e-03, -5.4884e-04, -8.4448e-04, -6.2485e-03, -1.2459e-02],\n",
      "          [-2.1057e-03,  4.2558e-04, -3.4924e-03, -1.2009e-02, -1.0063e-02],\n",
      "          [-1.8082e-03, -1.4877e-03, -8.6823e-03, -1.1414e-02, -7.9041e-03]],\n",
      "\n",
      "         [[-3.2349e-03, -3.6278e-03, -1.6508e-03, -7.9346e-04, -1.3571e-03],\n",
      "          [-8.1482e-03, -5.2643e-03, -5.7602e-04, -2.5749e-03, -8.4305e-03],\n",
      "          [-3.2787e-03, -1.0986e-03, -4.1351e-03, -9.8495e-03, -1.0605e-02],\n",
      "          [ 3.8872e-03, -2.6932e-03, -1.2550e-02, -1.3535e-02, -1.0849e-02],\n",
      "          [-5.6763e-03, -1.5167e-02, -1.5182e-02, -1.2001e-02, -6.9618e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-8.6367e-05,  1.4105e-03,  1.1883e-03, -2.9564e-04, -1.4496e-03],\n",
      "          [ 1.4114e-03,  1.3409e-03,  1.1387e-03, -4.2439e-04, -1.7080e-03],\n",
      "          [ 1.8358e-04, -8.2445e-04,  2.3246e-04, -2.5201e-04, -1.2159e-03],\n",
      "          [ 1.5223e-04, -1.0185e-03, -5.9009e-06,  2.0146e-04, -1.5724e-04],\n",
      "          [ 5.8293e-05, -8.4817e-05,  3.0565e-04,  6.6137e-04, -1.0520e-04]],\n",
      "\n",
      "         [[-1.4889e-04, -1.1063e-03, -1.4639e-03, -4.5085e-04,  1.6270e-03],\n",
      "          [ 8.0109e-04,  5.2309e-04,  2.6774e-04,  1.3485e-03,  2.4433e-03],\n",
      "          [ 2.3518e-03,  2.0580e-03,  2.2240e-03,  2.4586e-03,  1.7872e-03],\n",
      "          [ 3.4542e-03,  2.5291e-03,  1.9264e-03,  1.8654e-03,  1.3943e-03],\n",
      "          [ 1.4849e-03,  1.8692e-03,  1.9474e-03,  1.5316e-03,  1.2045e-03]],\n",
      "\n",
      "         [[-3.8719e-04,  6.0940e-04,  8.3566e-05,  3.4547e-04,  8.7678e-05],\n",
      "          [-7.4530e-04,  3.3855e-04,  2.8491e-04,  4.3035e-04, -3.0577e-05],\n",
      "          [-3.0160e-04, -5.2691e-04, -5.6219e-04,  6.6757e-06, -5.4359e-05],\n",
      "          [ 1.0490e-03, -1.1998e-04, -4.1699e-04, -4.0746e-04, -5.6088e-05],\n",
      "          [ 6.4611e-04, -1.7202e-04, -3.3545e-04,  4.9925e-04,  1.2517e-04]],\n",
      "\n",
      "         [[-1.5354e-04,  7.6580e-04,  6.4135e-04, -1.5104e-04, -7.4863e-04],\n",
      "          [ 1.5044e-04,  3.5477e-04, -3.5596e-04, -7.8583e-04, -9.7752e-04],\n",
      "          [-6.0701e-04, -5.7888e-04, -2.3162e-04, -3.3236e-04, -1.9205e-04],\n",
      "          [-3.9387e-04, -5.2071e-04,  1.6356e-04,  1.4842e-05, -2.3925e-04],\n",
      "          [-2.6822e-06, -7.7367e-05, -2.7359e-05,  2.5845e-04, -1.3602e-04]],\n",
      "\n",
      "         [[-7.5483e-04, -6.3944e-04,  7.3671e-05,  9.4318e-04,  1.9007e-03],\n",
      "          [-2.2674e-04, -3.5381e-04,  4.7326e-05,  7.8011e-04,  1.4696e-03],\n",
      "          [ 5.9843e-04,  5.9485e-05, -6.9237e-04, -1.3876e-04, -4.2915e-05],\n",
      "          [ 2.8634e-04, -1.3971e-04, -6.7472e-04, -5.4836e-04, -2.9540e-04],\n",
      "          [ 1.0557e-03, -9.9659e-05, -1.0777e-03, -2.9516e-04, -1.6367e-04]],\n",
      "\n",
      "         [[-6.9809e-04,  8.0538e-04,  1.8444e-03,  9.6464e-04,  5.1069e-04],\n",
      "          [ 8.2493e-04,  2.4681e-03,  3.9482e-03,  1.8663e-03,  2.0540e-04],\n",
      "          [ 3.6583e-03,  3.8166e-03,  2.3575e-03,  1.2102e-03,  1.6248e-04],\n",
      "          [ 1.9045e-03,  8.7500e-04,  1.4572e-03,  3.3140e-04, -5.2261e-04],\n",
      "          [-2.2221e-03, -1.3757e-04,  1.7715e-04,  1.9455e-04, -2.2960e-04]]],\n",
      "\n",
      "\n",
      "        [[[-2.1191e-03, -3.2349e-03, -4.0932e-03, -3.8795e-03, -2.9526e-03],\n",
      "          [-5.4321e-03, -7.3280e-03, -5.5923e-03, -1.4286e-03, -2.5539e-03],\n",
      "          [-4.0550e-03, -9.3231e-03, -1.1528e-02,  1.5163e-03, -3.4542e-03],\n",
      "          [-3.6907e-03, -1.2894e-02, -9.8190e-03,  5.5599e-04, -3.1471e-03],\n",
      "          [-4.5738e-03, -9.3842e-03, -5.3024e-03, -4.5848e-04, -2.5253e-03]],\n",
      "\n",
      "         [[-1.0223e-02, -4.9248e-03, -3.9291e-03, -4.8561e-03, -6.5041e-03],\n",
      "          [-2.5978e-03, -3.8123e-04,  2.7275e-03, -4.3106e-03, -4.9095e-03],\n",
      "          [-3.9101e-03,  2.0361e-04,  3.5877e-03, -4.0436e-03, -6.3286e-03],\n",
      "          [-5.8784e-03,  7.0035e-05,  1.3485e-03, -7.7782e-03, -8.7128e-03],\n",
      "          [-4.2992e-03, -4.0398e-03, -6.3019e-03, -9.9792e-03, -8.9264e-03]],\n",
      "\n",
      "         [[ 3.5667e-04, -2.7943e-04, -2.7609e-04, -4.6277e-04, -3.7646e-04],\n",
      "          [-1.3838e-03, -1.4210e-03, -3.9253e-03, -2.7809e-03, -1.0595e-03],\n",
      "          [-1.3828e-03, -2.7275e-03, -7.3433e-03, -2.8133e-03, -1.1778e-03],\n",
      "          [-1.0653e-03, -4.5090e-03, -4.9858e-03, -9.9182e-04, -8.4496e-04],\n",
      "          [ 4.1008e-04, -2.0123e-03, -1.8711e-03, -5.4789e-04, -1.4706e-03]],\n",
      "\n",
      "         [[-3.4714e-03, -4.5204e-03, -6.1760e-03, -4.1962e-03, -2.8286e-03],\n",
      "          [-3.8414e-03, -2.1420e-03, -2.9011e-03, -3.4695e-03, -1.4830e-03],\n",
      "          [-5.0831e-04, -2.5215e-03, -3.1605e-03, -8.8739e-04, -1.8549e-03],\n",
      "          [-1.9026e-03, -4.5090e-03, -2.0199e-03,  3.9244e-04, -1.0529e-03],\n",
      "          [-1.9512e-03, -2.8801e-03, -8.4448e-04, -1.0405e-03, -2.4300e-03]],\n",
      "\n",
      "         [[-8.0299e-04,  1.0443e-03,  1.0195e-03, -2.7180e-03, -2.0332e-03],\n",
      "          [ 2.5024e-03,  2.6169e-03, -1.9064e-03, -8.3923e-03, -4.3869e-03],\n",
      "          [ 1.6775e-03, -1.7672e-03, -1.7195e-03, -1.1032e-02, -6.4240e-03],\n",
      "          [-1.0319e-03, -8.9550e-04, -7.0000e-04, -1.1169e-02, -6.1951e-03],\n",
      "          [ 6.8808e-04, -1.6060e-03, -5.1765e-03, -8.1406e-03, -2.5024e-03]],\n",
      "\n",
      "         [[ 4.7035e-03,  5.5885e-03,  5.8479e-03, -3.3426e-04, -2.9793e-03],\n",
      "          [ 3.2673e-03, -1.5488e-03, -1.2417e-03, -9.9003e-05, -1.5469e-03],\n",
      "          [-6.8512e-03, -4.7607e-03, -2.7885e-03, -4.2801e-03, -5.8327e-03],\n",
      "          [-3.1223e-03, -3.7556e-03, -1.1192e-02, -9.7656e-03, -8.0795e-03],\n",
      "          [-4.2725e-03, -1.0323e-02, -1.2428e-02, -6.9199e-03, -3.9177e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.7895e-04,  6.7949e-04,  2.6741e-03,  2.9888e-03,  1.0004e-03],\n",
      "          [ 5.2309e-04,  2.3403e-03,  3.1834e-03,  2.3537e-03,  1.7273e-04],\n",
      "          [ 1.2960e-03,  3.4084e-03,  2.5043e-03,  3.6740e-04, -2.8992e-04],\n",
      "          [ 1.9140e-03,  2.3232e-03,  4.7493e-04, -4.1056e-04,  7.2622e-04],\n",
      "          [ 1.0138e-03,  1.1940e-03,  5.6362e-04,  1.6284e-04,  1.6050e-03]],\n",
      "\n",
      "         [[ 1.7414e-03,  2.2202e-03,  9.0981e-04, -8.9264e-04, -6.5422e-04],\n",
      "          [ 1.6918e-03,  2.1958e-04, -1.3895e-03, -1.6890e-03, -9.5987e-04],\n",
      "          [ 1.2989e-03, -8.6832e-04, -2.0847e-03, -1.4029e-03, -3.8505e-04],\n",
      "          [ 1.5869e-03, -1.7285e-04, -4.3583e-04,  2.5201e-04,  4.3392e-05],\n",
      "          [ 2.6264e-03,  1.4534e-03,  3.4714e-04,  5.0354e-04, -5.2989e-05]],\n",
      "\n",
      "         [[-3.0541e-04,  2.0456e-04,  1.1265e-04,  8.9216e-04, -7.3314e-06],\n",
      "          [-3.4714e-04,  1.2350e-04,  4.2319e-04,  7.5579e-04,  3.3796e-05],\n",
      "          [-4.1580e-04,  1.1225e-03,  8.9455e-04,  4.9496e-04,  5.3740e-04],\n",
      "          [-1.1981e-04,  3.3140e-04,  5.8413e-04,  4.8304e-04,  4.9543e-04],\n",
      "          [-3.5942e-05, -1.4055e-04,  5.4312e-04,  4.7278e-04,  5.8746e-04]],\n",
      "\n",
      "         [[-1.7834e-04,  4.3893e-04,  1.7786e-03,  1.9407e-03,  9.5415e-04],\n",
      "          [-1.9550e-04,  9.4366e-04,  2.0924e-03,  1.3418e-03,  2.0337e-04],\n",
      "          [-3.5954e-04,  8.6451e-04,  7.8154e-04, -2.9862e-05, -5.4538e-05],\n",
      "          [ 5.4073e-04, -1.8489e-04, -5.1832e-04, -3.4451e-04,  3.0112e-04],\n",
      "          [-4.5300e-05, -3.7932e-04,  2.3925e-04,  6.8378e-04,  6.4945e-04]],\n",
      "\n",
      "         [[ 1.7846e-04,  8.8453e-04, -3.6430e-04, -5.3024e-04,  4.9877e-04],\n",
      "          [-2.3544e-05, -3.5167e-05, -2.7537e-04,  6.1095e-05,  9.1410e-04],\n",
      "          [ 5.0926e-04, -7.2575e-04, -1.1311e-03,  6.8617e-04,  1.4591e-03],\n",
      "          [-4.8423e-04, -1.7929e-03, -7.7057e-04,  4.9543e-04,  5.4979e-04],\n",
      "          [-2.8801e-04, -6.1417e-04, -3.2568e-04, -2.0945e-04, -8.9943e-05]],\n",
      "\n",
      "         [[-4.5478e-05,  3.2163e-04, -6.0987e-04, -4.4322e-04, -2.1231e-04],\n",
      "          [ 1.1581e-04, -1.3185e-04, -7.8201e-04, -2.9087e-04,  8.0252e-04],\n",
      "          [ 4.6253e-04,  1.9729e-05,  1.0529e-03,  2.4586e-03,  1.9274e-03],\n",
      "          [ 2.5272e-05,  2.3594e-03,  3.0155e-03,  2.5558e-03,  1.9855e-03],\n",
      "          [ 9.5940e-04,  1.8177e-03,  7.3195e-04,  3.2830e-04,  7.9155e-04]]]],\n",
      "       device='cuda:0', dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "print(LOG)\n",
    "print(net_g.conv2.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "21a737a5-5a7e-494e-a545-491e9772bb09",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/y-neo/work2/workspace/docker/workspace/LeNet_MNIST/model_quant_int8.pth', 'to int8', 'fc3_load', 'to int8', 'fc3_load', 'fc3_load', 'fc3_load', 'fc3_load', 'fc3_load', 'fc3_load', 'fc3_load', 'fc3_load', 'fc3_load', 'fc3_load', 'fc3_load', 'fc3_load', 'fc3_load', 'fc3_load']\n",
      "tensor([-4.8875e+01, -7.5250e+01, -1.2625e+01, -3.3184e+00, -1.9375e+02,\n",
      "         8.4351e-02, -7.8562e+01, -5.3406e+01, -6.4438e+01, -1.4288e+02,\n",
      "        -1.4086e+01, -9.9625e+01,  7.1960e-02, -1.6412e+02, -1.4038e+02,\n",
      "        -4.6777e-01, -5.0625e+01, -1.6025e+02, -3.1359e+01,  4.3274e-02,\n",
      "        -3.0900e+02, -1.0633e+01, -2.3975e+02, -1.0002e-02, -3.3625e+01,\n",
      "         2.6758e-01, -8.6562e+01,  2.6886e-02, -9.9938e+01, -5.7465e-02,\n",
      "        -2.4525e+02,  1.7578e-01, -1.5838e+02, -1.6925e+02, -2.6250e+02,\n",
      "        -3.6125e+02, -1.5650e+02, -5.1844e+01, -1.1367e+01,  7.9590e-02,\n",
      "        -6.8848e-02, -1.2850e+02, -3.3375e+02, -1.1256e+02,  8.0643e-03,\n",
      "        -2.0225e+02, -5.1956e-03,  1.0828e-01, -1.2378e-01, -9.6497e-02,\n",
      "        -2.1543e+00, -1.7125e+02, -6.6188e+01, -1.9104e-01, -7.0750e+01,\n",
      "         2.9102e-01, -1.9608e-02, -8.0125e+01, -7.0875e+01, -1.1706e+02,\n",
      "         1.3818e+00, -3.2109e+00, -1.3125e+02, -2.5750e+02, -2.6109e+01,\n",
      "         2.0374e-01, -1.0394e+02, -3.3719e+01, -1.9238e+02,  1.3535e-02,\n",
      "        -7.7295e-01, -5.9062e+01, -8.1375e+01, -1.2400e+02, -1.9045e-03,\n",
      "        -1.6812e+01, -1.6550e+02, -2.3575e+02, -2.5900e+02, -2.4384e-02,\n",
      "        -2.5625e+02,  4.7779e-04, -2.1050e+02, -1.0331e+02], device='cuda:0',\n",
      "       dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "print(LOG)\n",
    "print(net_g.fc3.weight.grad[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fd96f43b-0bf3-4312-a56b-e6ffcce0f9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "da65e94f-7154-4180-88f9-de9b251c3ce4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'conv1_01'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-3734ac82456b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconv1_optim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"conv1_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mnet_g\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv1_optim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_read_fileobject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'conv1_01'"
     ]
    }
   ],
   "source": [
    "conv1_optim = joblib.load(\"conv1_\"+str(num).zfill(2))\n",
    "for i in range(6):\n",
    "    for j in range(5):\n",
    "        for k in range(5):\n",
    "            net_g.conv1.weight.data[i][0][j][k] = conv1_optim[i][0][j][k]\n",
    "LOG.append(\"conv1_load\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "9ffa5396-26dd-4cc7-9862-d9d329f51c14",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./conv1_optim_latest']"
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1_optim = joblib.load(\"conv1_optim\")\n",
    "\n",
    "joblib.dump(conv1_optim, \"./conv1_optim_latest\",compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "id": "1bdd3d9a-a7b8-45ae-ae16-70391368515d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conv2_optim = joblib.load(\"conv2_optim\")\n",
    "for h in range(16):\n",
    "    for i in range(6):\n",
    "        for j in range(5):\n",
    "            for k in range(5):\n",
    "                net_g.conv2.weight.data[h][i][j][k] = conv2_optim[h][i][j][k]\n",
    "LOG.append(\"conv2_load\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "518c811f-4c41-4bd3-9e0c-30809d7dca2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fc1_optim = joblib.load(\"fc1_optim\")\n",
    "for i in range(128):\n",
    "    for j in range(256):\n",
    "        net_g.fc1.weight.data[i][j] = fc1_optim[i][j]\n",
    "LOG.append(\"fc1_load\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "cb3cecd7-d4df-4470-bea4-2e70b033e4de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fc2_optim = joblib.load(\"fc2_optim\")\n",
    "for i in range(84):\n",
    "    for j in range(128):\n",
    "        net_g.fc2.weight.data[i][j] = fc2_optim[i][j]\n",
    "LOG.append(\"fc2_load\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "968aecdf-f2ef-42c3-bf38-447fc7c89d9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fc3_optim = joblib.load(\"fc3_optim\")\n",
    "for i in range(10):\n",
    "    for j in range(84):\n",
    "        net_g.fc3.weight.data[i][j] = fc3_optim[i][j]\n",
    "LOG.append(\"fc3_load\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "6c5fca9e-f39c-4551-8c05-11df45d834d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/y-neo/work2/workspace/optim/grad/fc3_grad']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(net_g.fc3.weight.grad, \"/home/y-neo/work2/workspace/optim/grad/fc3_grad\",compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "7e7bc2fc-8085-4763-ba4f-16e6e1e7857c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/y-neo/work2/workspace/optim/grad/fc1_grad']"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(net_g.fc1.weight.grad, \"/home/y-neo/work2/workspace/optim/grad/fc1_grad\",compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4c67a8ee-f01c-4d0a-8179-9052cd3028ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/y-neo/work2/workspace/auto_optim/grad/fc3_grad']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(net_g.conv1.weight.grad, \"/home/y-neo/work2/workspace/optim/grad/conv1_grad\",compress=3)\n",
    "joblib.dump(net_g.conv2.weight.grad, \"/home/y-neo/work2/workspace/optim/grad/conv2_grad\",compress=3)\n",
    "joblib.dump(net_g.fc1.weight.grad, \"/home/y-neo/work2/workspace/optim/grad/fc1_grad\",compress=3)\n",
    "joblib.dump(net_g.fc2.weight.grad, \"/home/y-neo/work2/workspace/optim/grad/fc2_grad\",compress=3)\n",
    "joblib.dump(net_g.fc3.weight.grad, \"/home/y-neo/work2/workspace/optim/grad/fc3_grad\",compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "3fc51af7-ea6f-457e-ae5a-fb4868ef14c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/y-neo/work2/workspace/optim/grad/fc1_grad']"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(net_g.fc1.weight.grad, \"/home/y-neo/work2/workspace/optim/grad/fc1_grad\",compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "eebb36ca-6457-4dd7-8d54-2b92fdfe29ee",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.2903e-03,  1.6296e-02,  3.4576e-02,  4.8553e-02,  2.7481e-02],\n",
      "          [-6.9008e-03,  4.8103e-03,  2.9556e-02,  3.6011e-02,  1.7838e-02],\n",
      "          [-1.2825e-02, -6.0129e-04,  1.3298e-02,  7.7133e-03,  1.7958e-03],\n",
      "          [-1.7578e-02, -1.3741e-02, -1.9226e-02, -9.3384e-03,  4.3526e-03],\n",
      "          [-1.9608e-02, -3.4546e-02, -3.7537e-02, -1.8158e-02,  1.6693e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3809e-02,  2.7657e-04,  1.2169e-03,  5.4283e-03,  1.2482e-02],\n",
      "          [ 1.6998e-02,  2.1835e-02,  1.4122e-02,  1.0345e-02,  1.1826e-02],\n",
      "          [ 2.8778e-02,  2.2369e-02,  1.3969e-02,  1.0017e-02,  1.1017e-02],\n",
      "          [ 2.2675e-02,  1.7197e-02,  4.0932e-03, -6.4182e-04, -2.5272e-03],\n",
      "          [ 9.8801e-03, -3.4657e-03, -8.8425e-03, -9.5215e-03, -1.8951e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.7595e-04,  1.2779e-02,  2.7084e-02,  2.4399e-02,  4.8866e-03],\n",
      "          [-5.3177e-03,  5.6686e-03,  1.8860e-02,  1.2955e-02, -1.7297e-04],\n",
      "          [-4.9019e-03,  6.8398e-03,  6.9237e-03,  3.7041e-03,  4.6501e-03],\n",
      "          [-1.0391e-02, -1.3329e-02, -7.4959e-03,  4.1275e-03,  1.1665e-02],\n",
      "          [-2.1530e-02, -2.6352e-02, -1.2276e-02,  5.3825e-03,  1.5572e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4319e-03,  5.1270e-03,  6.6338e-03,  3.6125e-03,  5.1193e-03],\n",
      "          [-7.9193e-03, -8.7891e-03, -3.6869e-03, -3.9520e-03, -1.2517e-06],\n",
      "          [-8.2703e-03, -1.3046e-02, -9.1400e-03, -5.8670e-03, -3.3607e-03],\n",
      "          [-8.4229e-03, -1.2070e-02, -1.1314e-02, -1.2093e-02, -6.7062e-03],\n",
      "          [ 2.4452e-03,  3.4466e-03, -4.5128e-03, -6.0310e-03, -6.3438e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1787e-02,  1.4668e-03, -2.6760e-03,  6.6042e-04,  1.3208e-03],\n",
      "          [ 8.5297e-03, -4.1580e-03, -5.3787e-03, -2.1496e-03, -1.9608e-03],\n",
      "          [ 5.4855e-03,  2.9659e-04, -5.6419e-03, -9.1629e-03, -6.9885e-03],\n",
      "          [ 4.6120e-03,  4.3526e-03, -3.1338e-03, -8.9722e-03, -8.0795e-03],\n",
      "          [-6.6853e-04,  3.7537e-03,  1.7776e-03, -1.1406e-03, -3.3627e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.9602e-02,  2.1194e-02,  1.9562e-02,  1.9104e-02,  8.7433e-03],\n",
      "          [ 3.8666e-02,  2.7985e-02,  2.5757e-02,  1.2810e-02,  9.1248e-03],\n",
      "          [ 4.3152e-02,  3.9276e-02,  3.1555e-02,  1.6235e-02,  9.0027e-03],\n",
      "          [ 5.3192e-02,  5.9082e-02,  4.9438e-02,  2.9846e-02,  2.5513e-02],\n",
      "          [ 5.8167e-02,  6.3477e-02,  4.7943e-02,  3.6804e-02,  4.2023e-02]]]],\n",
      "       device='cuda:0', dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "print(net_g.conv1.weight.grad)\n",
    "#print(net_g.conv1.weight.data)\n",
    "#print(net_g.conv1.weight.data*128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a2ee0096-a45f-42c8-a211-a61a9bafdceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9420000314712524 0.17567115783691414\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.cuda.FloatTensor) and weight type (torch.cuda.HalfTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-c5e977b284ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mpre_w\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_g\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0moptimizer_g\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet_g\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-8265ea2a0ae2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m84\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_flat_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    438\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    439\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 440\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.cuda.HalfTensor) should be the same"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_g = optim.SGD(net_g.parameters(), lr=0.001, momentum=0.9)\n",
    "epochs = 10\n",
    "count = 0\n",
    "pre_w = [0,0,0,0,0]\n",
    "post_w = [0,0,0,0,0]\n",
    "grad = [0,0,0,0,0]\n",
    "\n",
    "acc, loss = test(net_g, test_loader, criterion)\n",
    "print(float(acc), loss)\n",
    "net_g.train()\n",
    "for data in train_loader:\n",
    "    inputs, labels = data[0].to(device), data[1].to(device)\n",
    "    pre_w[0] = copy.deepcopy(net_g.conv1.weight.data)\n",
    "    pre_w[1] = copy.deepcopy(net_g.conv2.weight.data)\n",
    "    pre_w[2] = copy.deepcopy(net_g.fc1.weight.data)\n",
    "    pre_w[3] = copy.deepcopy(net_g.fc2.weight.data)\n",
    "    pre_w[4] = copy.deepcopy(net_g.fc3.weight.data)\n",
    "    optimizer_g.zero_grad()\n",
    "    outputs = net_g(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer_g.step()\n",
    "    post_w[0] = copy.deepcopy(net_g.conv1.weight.data)\n",
    "    post_w[1] = copy.deepcopy(net_g.conv2.weight.data)\n",
    "    post_w[2] = copy.deepcopy(net_g.fc1.weight.data)\n",
    "    post_w[3] = copy.deepcopy(net_g.fc2.weight.data)\n",
    "    post_w[4] = copy.deepcopy(net_g.fc3.weight.data)\n",
    "    acc = (outputs.argmax(dim=1) == labels).float().mean()\n",
    "    grad[0] = copy.deepcopy(net_g.conv1.weight.grad)\n",
    "    grad[1] = copy.deepcopy(net_g.conv2.weight.grad)\n",
    "    grad[2] = copy.deepcopy(net_g.fc1.weight.grad)\n",
    "    grad[3] = copy.deepcopy(net_g.fc2.weight.grad)\n",
    "    grad[4] = copy.deepcopy(net_g.fc3.weight.grad)\n",
    "    print(grad[4][0])\n",
    "    print((post_w[4]-pre_w[4])[0])\n",
    "    break\n",
    "acc, loss = test(net_g, test_loader, criterion)\n",
    "print(float(acc), loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d1781350-021f-44df-9542-5f09147a0323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 : train acc. 0.881 train loss 0.405\n",
      "Epoch 1 : test acc. 0.897 test loss 0.357\n",
      "Epoch 2 : train acc. 0.904 train loss 0.332\n",
      "Epoch 2 : test acc. 0.913 test loss 0.302\n",
      "Epoch 3 : train acc. 0.915 train loss 0.286\n",
      "Epoch 3 : test acc. 0.925 test loss 0.261\n",
      "Epoch 4 : train acc. 0.927 train loss 0.251\n",
      "Epoch 4 : test acc. 0.933 test loss 0.233\n",
      "Epoch 5 : train acc. 0.933 train loss 0.231\n",
      "Epoch 5 : test acc. 0.937 test loss 0.216\n",
      "Epoch 6 : train acc. 0.934 train loss 0.213\n",
      "Epoch 6 : test acc. 0.939 test loss 0.202\n",
      "Epoch 7 : train acc. 0.941 train loss 0.195\n",
      "Epoch 7 : test acc. 0.944 test loss 0.190\n",
      "Epoch 8 : train acc. 0.944 train loss 0.184\n",
      "Epoch 8 : test acc. 0.947 test loss 0.174\n",
      "Epoch 9 : train acc. 0.949 train loss 0.173\n",
      "Epoch 9 : test acc. 0.949 test loss 0.166\n",
      "Epoch 10 : train acc. 0.951 train loss 0.163\n",
      "Epoch 10 : test acc. 0.952 test loss 0.156\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b39e22-3460-4af2-9284-92e3d9a6f3fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
